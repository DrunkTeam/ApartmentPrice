Caching disabled explicitly for transform.

Step transform has started.

By default, the PandasMaterializer stores data as a .csv file. If you want to store data more efficiently, you can install pyarrow by running 'pip install pyarrow'. This will allow PandasMaterializer to automatically store the data as a .parquet file instead.

/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/zenml/materializers/pandas_materializer.py:94: UserWarning: Could not infer format, so each element will be parsed individually, falling back to dateutil. To ensure parsing is consistent and as-expected, please specify a format.
  df = pd.read_csv(f, index_col=0, parse_dates=True)


collecting all words and their counts

PROGRESS: at sentence #0, processed 0 words, keeping 0 word types

PROGRESS: at sentence #10000, processed 46432 words, keeping 320 word types

collected 320 word types from a corpus of 58294 raw words and 12562 sentences

Creating a fresh vocabulary

Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 320 unique words (100.00% of original 320, drops 0)', 'datetime': '2024-07-20T01:34:50.137217', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 58294 word corpus (100.00% of original 58294, drops 0)', 'datetime': '2024-07-20T01:34:50.137334', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

deleting the raw counts dictionary of 320 items

sample=0.001 downsamples 79 most-common words

Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 30361.279602895538 word corpus (52.1%% of prior 58294)', 'datetime': '2024-07-20T01:34:50.138839', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

estimated required memory for 320 words and 10 dimensions: 185600 bytes

resetting layer weights

Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-07-20T01:34:50.140388', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'build_vocab'}

Word2Vec lifecycle event {'msg': 'training model with 4 workers on 320 vocabulary and 10 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-07-20T01:34:50.140488', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}

EPOCH 0: training on 58294 raw words (30357 effective words) took 0.0s, 1601287 effective words/s

EPOCH 1: training on 58294 raw words (30282 effective words) took 0.1s, 484568 effective words/s

EPOCH 2: training on 58294 raw words (30353 effective words) took 0.0s, 1597239 effective words/s

EPOCH 3: training on 58294 raw words (30486 effective words) took 0.0s, 2610056 effective words/s

EPOCH 4: training on 58294 raw words (30350 effective words) took 0.0s, 2558842 effective words/s

Word2Vec lifecycle event {'msg': 'training on 291470 raw words (151828 effective words) took 0.2s, 967579 effective words/s', 'datetime': '2024-07-20T01:34:50.297491', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}

Word2Vec lifecycle event {'params': 'Word2Vec<vocab=320, vector_size=10, alpha=0.025>', 'datetime': '2024-07-20T01:34:50.297641', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'created'}

collecting all words and their counts

PROGRESS: at sentence #0, processed 0 words, keeping 0 word types

PROGRESS: at sentence #10000, processed 19145 words, keeping 3477 word types

collected 3790 word types from a corpus of 24075 raw words and 12562 sentences

Creating a fresh vocabulary

Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 3790 unique words (100.00% of original 3790, drops 0)', 'datetime': '2024-07-20T01:34:50.466806', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 24075 word corpus (100.00% of original 24075, drops 0)', 'datetime': '2024-07-20T01:34:50.467072', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

deleting the raw counts dictionary of 3790 items

sample=0.001 downsamples 57 most-common words

Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 21626.328701985825 word corpus (89.8%% of prior 24075)', 'datetime': '2024-07-20T01:34:50.480077', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

estimated required memory for 3790 words and 2 dimensions: 1955640 bytes

resetting layer weights

Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-07-20T01:34:50.494840', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'build_vocab'}

Word2Vec lifecycle event {'msg': 'training model with 4 workers on 3790 vocabulary and 2 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-07-20T01:34:50.494959', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}

EPOCH 0: training on 24075 raw words (21629 effective words) took 0.0s, 1400695 effective words/s

EPOCH 1: training on 24075 raw words (21626 effective words) took 0.0s, 1387197 effective words/s

EPOCH 2: training on 24075 raw words (21613 effective words) took 0.0s, 1391093 effective words/s

EPOCH 3: training on 24075 raw words (21572 effective words) took 0.0s, 1398879 effective words/s

EPOCH 4: training on 24075 raw words (21623 effective words) took 0.0s, 1373118 effective words/s

Word2Vec lifecycle event {'msg': 'training on 120375 raw words (108063 effective words) took 0.1s, 1259730 effective words/s', 'datetime': '2024-07-20T01:34:50.580824', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}

Word2Vec lifecycle event {'params': 'Word2Vec<vocab=3790, vector_size=2, alpha=0.025>', 'datetime': '2024-07-20T01:34:50.581015', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'created'}

collecting all words and their counts

PROGRESS: at sentence #0, processed 0 words, keeping 0 word types

PROGRESS: at sentence #10000, processed 46432 words, keeping 320 word types

collected 320 word types from a corpus of 58294 raw words and 12562 sentences

Creating a fresh vocabulary

Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 320 unique words (100.00% of original 320, drops 0)', 'datetime': '2024-07-20T01:34:50.828733', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 58294 word corpus (100.00% of original 58294, drops 0)', 'datetime': '2024-07-20T01:34:50.828846', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

deleting the raw counts dictionary of 320 items

sample=0.001 downsamples 79 most-common words

Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 30361.279602895538 word corpus (52.1%% of prior 58294)', 'datetime': '2024-07-20T01:34:50.830148', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'prepare_vocab'}

estimated required memory for 320 words and 3 dimensions: 167680 bytes

resetting layer weights

Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-07-20T01:34:50.831821', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'build_vocab'}

Word2Vec lifecycle event {'msg': 'training model with 4 workers on 320 vocabulary and 3 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-07-20T01:34:50.831920', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}

EPOCH 0: training on 58294 raw words (30515 effective words) took 0.0s, 1604476 effective words/s

EPOCH 1: training on 58294 raw words (30335 effective words) took 0.0s, 1653134 effective words/s

EPOCH 2: training on 58294 raw words (30411 effective words) took 0.0s, 1648561 effective words/s

EPOCH 3: training on 58294 raw words (30243 effective words) took 0.0s, 1584022 effective words/s

EPOCH 4: training on 58294 raw words (30487 effective words) took 0.0s, 2399717 effective words/s

Word2Vec lifecycle event {'msg': 'training on 291470 raw words (151991 effective words) took 0.1s, 1511734 effective words/s', 'datetime': '2024-07-20T01:34:50.932535', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'train'}

Word2Vec lifecycle event {'params': 'Word2Vec<vocab=320, vector_size=3, alpha=0.025>', 'datetime': '2024-07-20T01:34:50.932691', 'gensim': '4.3.2', 'python': '3.11.9 (main, Apr 19 2024, 11:43:47) [Clang 14.0.6 ]', 'platform': 'macOS-14.5-arm64-arm-64bit', 'event': 'created'}

Failed to run step transform.

"None of [Index(['Move_in_date_year'], dtype='object')] are in the [columns]"
Traceback (most recent call last):
  File "/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py", line 230, in launch
    self._run_step(
  File "/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py", line 460, in _run_step
    self._run_step_without_step_operator(
  File "/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/zenml/orchestrators/step_launcher.py", line 535, in _run_step_without_step_operator
    runner.run(
  File "/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/zenml/orchestrators/step_runner.py", line 199, in run
    return_values = step_instance.call_entrypoint(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/zenml/steps/base_step.py", line 606, in call_entrypoint
    return self.entrypoint(**validated_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/Sofa/Desktop/Innopolis/MLOps/ApartmentPrice/services/airflow/dags/data_prepare.py", line 39, in transform
    X, y = preprocess_data(df)
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/Sofa/Desktop/Innopolis/MLOps/ApartmentPrice/src/data.py", line 248, in preprocess_data
    df[[scale]] = scaler.fit_transform(df[[scale]])
                                       ~~^^^^^^^^^
  File "/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/pandas/core/frame.py", line 4108, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6200, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/opt/homebrew/anaconda3/envs/mlops_9/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6249, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['Move_in_date_year'], dtype='object')] are in the [columns]"

